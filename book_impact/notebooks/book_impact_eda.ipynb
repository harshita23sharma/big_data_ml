{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "# from pyspark.sql.types import *\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:15 WARN Utils: Your hostname, Harshitas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.102 instead (on interface en0)\n",
      "23/12/31 00:27:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/31 00:27:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/harshita/.pyenv/versions/3.10.0/lib/python3.10/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder \\\n",
    "            .master(\"local[2]\") \\\n",
    "            .appName(\"book_impact_eda\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.load('/Users/harshita/Downloads/books_task.csv', \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header=True, \n",
    "                      inferSchema=True,\n",
    "                      escape='\"' \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------------+-------------+-----------------------------+-----------------+\n",
      "|_c0|Title                                |description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |authors            |publisher              |publishedDate|categories                   |Impact           |\n",
      "+---+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------------+-------------+-----------------------------+-----------------+\n",
      "|0  |Its Only Art If Its Well Hung!       |NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |['Julie Strain']   |Smithsonian Institution|1996         |['Comics & Graphic Novels']  |784.3039243054303|\n",
      "|1  |Dr. Seuss: American Icon             |Philip Nel takes a fascinating look into the key aspects of Seuss's career - his poetry, politics, art, marketing, and place in the popular imagination.\" \"Nel argues convincingly that Dr. Seuss is one of the most influential poets in America. His nonsense verse, like that of Lewis Carroll and Edward Lear, has changed language itself, giving us new words like \"nerd.\" And Seuss's famously loopy artistic style - what Nel terms an \"energetic cartoon surrealism\" - has been equally important, inspiring artists like filmmaker Tim Burton and illustrator Lane Smith. --from back cover                                                                                                                                                                                                                                                                                                                                                                                                                                                             |['Philip Nel']     |A&C Black              |2005-01-01   |['Biography & Autobiography']|825.4655354138016|\n",
      "|2  |Wonderful Worship in Smaller Churches|This resource includes twelve principles in understanding small church worship, fifteen practices for planning worship with fewer than 100 people, and suggestions for congregational study.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |['David R. Ray']   |OUP USA                |2000         |['Religion']                 |841.7053210126119|\n",
      "|3  |Whispers of the Wicked Saints        |Julia Thomas finds her life spinning out of control after the death of her husband, Richard. Julia turns to her minister for comfort when she finds herself falling for him with a passion that is forbidden by the church. Heath Sparks is a man of God who is busy taking care of his quadriplegic wife who was seriously injured in a sever car accident. In an innocent effort to reach out to a lonely member of his church, Heath finds himself as the man and not the minister as Heath and Julia surrender their bodies to each other and face the wrath of God. Julia finds herself in over her head as she faces a deadly disease, the loss of her home and whispers about her wicked affair. Julia leaves the states offering her body as a living sacrifice in hopes of finding a cure while her heart remains thousands of miles away hoping to one day reunite with the man who holds it hostage.Whispers of the Wicked Saints is a once in a lifetime romance that is breath taking, defying all the rules of romance and bending the laws of love.|['Veronica Haddon']|iUniverse              |2005-02      |['Fiction']                  |666.4265418233589|\n",
      "+---+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+-----------------------+-------------+-----------------------------+-----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df=df.drop(\"_c0\")\n",
    "df.show(4,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-----+\n",
      "|publisher                    |count|\n",
      "+-----------------------------+-----+\n",
      "|L B I Law & Business Inst    |1    |\n",
      "|Christian Writers Institute  |1    |\n",
      "|X. J. Kennedy Poetry Prize   |1    |\n",
      "|Velocity Pub                 |1    |\n",
      "|Sarabande Books              |1    |\n",
      "|Natural Law and Enlightenment|1    |\n",
      "|Love Line Books              |1    |\n",
      "|Rosarius Publishing House    |1    |\n",
      "|Editorial Everest            |1    |\n",
      "|OTexts                       |1    |\n",
      "|Lawbook Exchange Limited     |1    |\n",
      "|Muska & Lipman Pub           |1    |\n",
      "|Gemma Halliday Publishing    |1    |\n",
      "|Mathyz                       |1    |\n",
      "|Emery Dalton Books           |1    |\n",
      "|Rarebooksclub.com            |1    |\n",
      "|Memoirs Unlimited            |1    |\n",
      "|Univ Science Books           |1    |\n",
      "|台灣五南圖書出版股份有限公司 |1    |\n",
      "|Penticton, B.C. : R. Gardner |1    |\n",
      "+-----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('publisher') \\\n",
    ".count() \\\n",
    ".sort(\"count\", ascending=True) \\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, isnan, col, round\n",
    "\n",
    "def find_row_missing_percentage(df):\n",
    "    \"\"\"\n",
    "    This function takes a PySpark DataFrame as input and returns a dataframe after adding \n",
    "    columns that have missing values and the percentage of missing values in each row.\n",
    "\n",
    "    :param df: PySpark DataFrame\n",
    "    :return: PySpark DataFrame with percentage missing in each row\n",
    "             List containing percentage of missing rows\n",
    "    \"\"\"\n",
    "    # Count the number of columns\n",
    "    total_columns = len(df.columns)\n",
    "\n",
    "    # Find rows with missing values and count missing values in each row\n",
    "    missing_values_df = df.select(\"*\",\n",
    "        sum(when(isnan(col(column_name)) | col(column_name).isNull(), 1).otherwise(0)\n",
    "            for column_name in df.columns).alias(\"missing_count\"))\n",
    "\n",
    "    # Calculate the percentage of missing values for each row\n",
    "    missing_percent_df = missing_values_df.withColumn(\"percent_missing\", col(\"missing_count\") / total_columns * 100)\n",
    "\n",
    "    missing_percent_df = missing_percent_df.withColumn(\"percent_missing\", round(missing_percent_df[\"percent_missing\"], 0))\n",
    "\n",
    "    # Calculate percentage of missing rows in dataframe \n",
    "    No_of_missRows = missing_percent_df.select('missing_count').where(missing_percent_df.missing_count>0).count()\n",
    "    Percent_miss_rows = No_of_missRows/df.count()\n",
    "\n",
    "    return missing_percent_df, Percent_miss_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "[Stage 8:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Missing Rows: 10.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_misscount, Percent_miss_rows = find_row_missing_percentage(df)\n",
    "\n",
    "# Print Percentage Missing Rows in the DataFrame\n",
    "print(\"% Missing Rows:\", \"{:.2%}\".format(Percent_miss_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "[Stage 11:==========================================================(2 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row value with max % missing: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print Row value having with max % missing\n",
    "your_max_value = df_misscount.agg({\"percent_missing\": \"max\"}).collect()[0][0]\n",
    "print(\"Row value with max % missing:\", your_max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+-------------+---------------+\n",
      "|_c0|               Title|         description|         authors|           publisher|publishedDate|          categories|           Impact|missing_count|percent_missing|\n",
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+-------------+---------------+\n",
      "|  0|Its Only Art If I...|                NULL|['Julie Strain']|Smithsonian Insti...|         1996|['Comics & Graphi...|784.3039243054303|            1|           13.0|\n",
      "|  1|Dr. Seuss: Americ...|Philip Nel takes ...|  ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|825.4655354138016|            0|            0.0|\n",
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+-------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    }
   ],
   "source": [
    "df_misscount.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Drop Columns with percent_missing > 60%\n",
    "# missing_threshold = 60\n",
    "# if Percent_miss_rows >= missing_threshold:\n",
    "#     filtered_df = df_misscount.filter(df_misscount.percent_missing < missing_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138724, 138724)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misscount.count(), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+\n",
      "|_c0|               Title|         description|         authors|           publisher|publishedDate|          categories|           Impact|\n",
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+\n",
      "|  0|Its Only Art If I...|                NULL|['Julie Strain']|Smithsonian Insti...|         1996|['Comics & Graphi...|784.3039243054303|\n",
      "|  1|Dr. Seuss: Americ...|Philip Nel takes ...|  ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|825.4655354138016|\n",
      "+---+--------------------+--------------------+----------------+--------------------+-------------+--------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql.types import IntegerType, StringType, NumericType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138724"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13872.400000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "138724*0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-----+\n",
      "|publisher                    |count|\n",
      "+-----------------------------+-----+\n",
      "|L B I Law & Business Inst    |1    |\n",
      "|Christian Writers Institute  |1    |\n",
      "|X. J. Kennedy Poetry Prize   |1    |\n",
      "|Velocity Pub                 |1    |\n",
      "|Sarabande Books              |1    |\n",
      "|Natural Law and Enlightenment|1    |\n",
      "|Love Line Books              |1    |\n",
      "|Rosarius Publishing House    |1    |\n",
      "|Editorial Everest            |1    |\n",
      "|OTexts                       |1    |\n",
      "|Lawbook Exchange Limited     |1    |\n",
      "|Muska & Lipman Pub           |1    |\n",
      "|Gemma Halliday Publishing    |1    |\n",
      "|Mathyz                       |1    |\n",
      "|Emery Dalton Books           |1    |\n",
      "|Rarebooksclub.com            |1    |\n",
      "|Memoirs Unlimited            |1    |\n",
      "|Univ Science Books           |1    |\n",
      "|台灣五南圖書出版股份有限公司 |1    |\n",
      "|Penticton, B.C. : R. Gardner |1    |\n",
      "+-----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('publisher') \\\n",
    ".count() \\\n",
    ".sort(\"count\", ascending=True) \\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "column = \"publishedDate\"\n",
    "df = df.withColumn(f\"{column}_year\", fn.regexp_extract(column, r\"\\b(\\d{4})\\b\", 1))\n",
    "df = df.withColumn(f\"{column}_month\", fn.regexp_extract(column, r\"(?<=-)(\\d{2})\", 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "|_c0|               Title|         description|             authors|           publisher|publishedDate|          categories|           Impact|publishedDate_year|publishedDate_month|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "|  0|Its Only Art If I...|                NULL|    ['Julie Strain']|Smithsonian Insti...|         1996|['Comics & Graphi...|784.3039243054303|              1996|                   |\n",
      "|  1|Dr. Seuss: Americ...|Philip Nel takes ...|      ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|825.4655354138016|              2005|                 01|\n",
      "|  2|Wonderful Worship...|This resource inc...|    ['David R. Ray']|             OUP USA|         2000|        ['Religion']|841.7053210126119|              2000|                   |\n",
      "|  3|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|           iUniverse|      2005-02|         ['Fiction']|666.4265418233589|              2005|                 02|\n",
      "|  5|The Church of Chr...|In The Church of ...|['Everett Ferguson']|Wm. B. Eerdmans P...|         1996|        ['Religion']|806.2161426995721|              1996|                   |\n",
      "|  8|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|     Tan Books & Pub|   2009-01-01|['Biography & Aut...|799.1626097737924|              2009|                 01|\n",
      "|  9|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|  Plympton PressIntl|         1995|  ['Social Science']|793.5048996688412|              1995|                   |\n",
      "| 10|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|    Berg Pub Limited|   1994-02-17|        ['Religion']|759.2711582939609|              1994|                 02|\n",
      "| 11|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|             OUP USA|      2005-07|       ['Reference']|847.0213715319953|              2005|                 07|\n",
      "| 12|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|            Sky Pony|   2018-11-06|['Juvenile Nonfic...|759.2711582939609|              2018|                 11|\n",
      "| 13|Vector Quantizati...|Herb Caen, a popu...|['Allen Gersho', ...|Springer Science ...|   2012-12-06|['Technology & En...|800.7812983400412|              2012|                 12|\n",
      "| 14|A husband for Kutani|First published i...|      ['Frank Owen']|Pickle Partners P...|   2018-02-27|         ['History']|805.5685400829483|              2018|                 02|\n",
      "| 16|The Ultimate Guid...|This collection b...|    ['Fiona Cownie']|Bloomsbury Publis...|   2010-01-28|             ['Law']| 715.333258667078|              2010|                 01|\n",
      "| 17|The Repeal of Ret...|At a time when Am...|['Rochelle Gurste...|       Hill and Wang|   2016-01-05|['Political Scien...|819.1083355137085|              2016|                 01|\n",
      "| 18|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|              Bantam|   2012-02-01|['Health & Fitness']|805.5685400829483|              2012|                 02|\n",
      "| 19|    Alaska Sourdough|\"Sourdough is a m...|     ['Ruth Allman']|Alaska Northwest ...|         1976|         ['Cooking']|802.8286093005349|              1976|                   |\n",
      "| 20|The Oxford Handbo...|A guide to curren...|     ['Robert Kane']|             OUP USA|   2011-07-27|      ['Philosophy']|831.0666668926963|              2011|                 07|\n",
      "| 21|Eyewitness Travel...|The DK Eyewitness...|['Dorling Kinders...|Smithsonian Insti...|   2015-06-15|          ['Europe']|787.1883918642411|              2015|                 06|\n",
      "| 22|Hunting The Hard Way|Thrilling stories...|     ['Howard Hill']|     Derrydale Press|   2000-04-26|['Sports & Recrea...|866.5822716179268|              2000|                 04|\n",
      "| 23|History of Magic ...|See the history o...|              ['DK']|Dorling Kindersle...|   2020-08-06|['Body, Mind & Sp...|763.9246402507372|              2020|                 08|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Group by publisher_lower and count  \n",
    "counts = df.groupBy(\"publisher\").count()\n",
    "\n",
    "# Join the counts back to the original DataFrame\n",
    "df_publisher_map_count = df.join(counts, on=\"publisher\", how=\"left\") \n",
    "\n",
    "df_publisher_map_count = df_publisher_map_count.select(\"publisher\", \"_c0\", F.col(\"count\").alias(\"publisher_count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:27:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , publisher\n",
      " Schema: _c0, publisher\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------------+\n",
      "|           publisher|_c0|publisher_count|\n",
      "+--------------------+---+---------------+\n",
      "|Springer Science ...| 13|            885|\n",
      "|Pickle Partners P...| 14|            234|\n",
      "|Alaska Northwest ...| 19|              6|\n",
      "|       Hill and Wang| 17|            313|\n",
      "|           A&C Black|  1|           1355|\n",
      "|              Bantam| 18|            511|\n",
      "|Wm. B. Eerdmans P...|  5|           2563|\n",
      "|     Tan Books & Pub|  8|           3635|\n",
      "|            Sky Pony| 12|              1|\n",
      "|Dorling Kindersle...| 23|            288|\n",
      "|    Berg Pub Limited| 10|           1169|\n",
      "|             OUP USA|  2|           1187|\n",
      "|             OUP USA| 11|           1187|\n",
      "|             OUP USA| 20|           1187|\n",
      "|     Derrydale Press| 22|            355|\n",
      "|  Plympton PressIntl|  9|              1|\n",
      "| Seven Stories Press| 24|             69|\n",
      "|           iUniverse|  3|           1057|\n",
      "|Smithsonian Insti...|  0|           3216|\n",
      "|Smithsonian Insti...| 21|           3216|\n",
      "+--------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_publisher_map_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:28:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , publisher\n",
      " Schema: _c0, publisher\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "[Stage 36:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------------+\n",
      "|           publisher|_c0|publisher_count|\n",
      "+--------------------+---+---------------+\n",
      "|Springer Science ...| 13|            885|\n",
      "|Pickle Partners P...| 14|            234|\n",
      "|Alaska Northwest ...| 19|              6|\n",
      "|       Hill and Wang| 17|            313|\n",
      "|           A&C Black|  1|           1355|\n",
      "|              Bantam| 18|            511|\n",
      "|Wm. B. Eerdmans P...|  5|           2563|\n",
      "|     Tan Books & Pub|  8|           3635|\n",
      "|             unknown| 12|              1|\n",
      "|Dorling Kindersle...| 23|            288|\n",
      "|    Berg Pub Limited| 10|           1169|\n",
      "|             OUP USA|  2|           1187|\n",
      "|             OUP USA| 11|           1187|\n",
      "|             OUP USA| 20|           1187|\n",
      "|     Derrydale Press| 22|            355|\n",
      "|             unknown|  9|              1|\n",
      "| Seven Stories Press| 24|             69|\n",
      "|           iUniverse|  3|           1057|\n",
      "|Smithsonian Insti...|  0|           3216|\n",
      "|Smithsonian Insti...| 21|           3216|\n",
      "+--------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Set the threshold for considering an author as 'unknown'\n",
    "unknown_threshold = 5\n",
    "\n",
    "# Replace the category with 'unknown' for less-known authors\n",
    "df_result = df_publisher_map_count.withColumn(\n",
    "    \"publisher\",\n",
    "    when(col(\"publisher_count\") < unknown_threshold, \"unknown\").otherwise(col(\"publisher\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:28:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , publisher\n",
      " Schema: _c0, publisher\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------------+\n",
      "|           publisher|_c0|publisher_count|\n",
      "+--------------------+---+---------------+\n",
      "|Springer Science ...| 13|            885|\n",
      "|Pickle Partners P...| 14|            234|\n",
      "|Alaska Northwest ...| 19|              6|\n",
      "|       Hill and Wang| 17|            313|\n",
      "|           A&C Black|  1|           1355|\n",
      "|              Bantam| 18|            511|\n",
      "|Wm. B. Eerdmans P...|  5|           2563|\n",
      "|     Tan Books & Pub|  8|           3635|\n",
      "|             unknown| 12|              1|\n",
      "|Dorling Kindersle...| 23|            288|\n",
      "|    Berg Pub Limited| 10|           1169|\n",
      "|             OUP USA|  2|           1187|\n",
      "|             OUP USA| 11|           1187|\n",
      "|             OUP USA| 20|           1187|\n",
      "|     Derrydale Press| 22|            355|\n",
      "|             unknown|  9|              1|\n",
      "| Seven Stories Press| 24|             69|\n",
      "|           iUniverse|  3|           1057|\n",
      "|Smithsonian Insti...|  0|           3216|\n",
      "|Smithsonian Insti...| 21|           3216|\n",
      "+--------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold for considering an author as 'unknown'\n",
    "unknown_threshold = 5\n",
    "\n",
    "# Replace the category with 'unknown' for less-known authors\n",
    "df_result = df_publisher_map_count.withColumn(\n",
    "    \"publisher\",\n",
    "    when(col(\"publisher_count\") < unknown_threshold, \"unknown\").otherwise(col(\"publisher\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result \\\n",
    ".groupBy('publisher') \\\n",
    ".count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:28:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , publisher\n",
      " Schema: _c0, publisher\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---------------+\n",
      "|           publisher|_c0|publisher_count|\n",
      "+--------------------+---+---------------+\n",
      "|Springer Science ...| 13|            885|\n",
      "|Pickle Partners P...| 14|            234|\n",
      "|Alaska Northwest ...| 19|              6|\n",
      "|       Hill and Wang| 17|            313|\n",
      "|           A&C Black|  1|           1355|\n",
      "|              Bantam| 18|            511|\n",
      "|Wm. B. Eerdmans P...|  5|           2563|\n",
      "|     Tan Books & Pub|  8|           3635|\n",
      "|             unknown| 12|              1|\n",
      "|Dorling Kindersle...| 23|            288|\n",
      "|    Berg Pub Limited| 10|           1169|\n",
      "|             OUP USA|  2|           1187|\n",
      "|             OUP USA| 11|           1187|\n",
      "|             OUP USA| 20|           1187|\n",
      "|     Derrydale Press| 22|            355|\n",
      "|             unknown|  9|              1|\n",
      "| Seven Stories Press| 24|             69|\n",
      "|           iUniverse|  3|           1057|\n",
      "|Smithsonian Insti...|  0|           3216|\n",
      "|Smithsonian Insti...| 21|           3216|\n",
      "+--------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "|_c0|               Title|         description|             authors|           publisher|publishedDate|          categories|           Impact|publishedDate_year|publishedDate_month|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "|  0|Its Only Art If I...|                NULL|    ['Julie Strain']|Smithsonian Insti...|         1996|['Comics & Graphi...|784.3039243054303|              1996|                   |\n",
      "|  1|Dr. Seuss: Americ...|Philip Nel takes ...|      ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|825.4655354138016|              2005|                 01|\n",
      "|  2|Wonderful Worship...|This resource inc...|    ['David R. Ray']|             OUP USA|         2000|        ['Religion']|841.7053210126119|              2000|                   |\n",
      "|  3|Whispers of the W...|Julia Thomas find...| ['Veronica Haddon']|           iUniverse|      2005-02|         ['Fiction']|666.4265418233589|              2005|                 02|\n",
      "|  5|The Church of Chr...|In The Church of ...|['Everett Ferguson']|Wm. B. Eerdmans P...|         1996|        ['Religion']|806.2161426995721|              1996|                   |\n",
      "|  8|Saint Hyacinth of...|The story for chi...|['Mary Fabyan Win...|     Tan Books & Pub|   2009-01-01|['Biography & Aut...|799.1626097737924|              2009|                 01|\n",
      "|  9|Rising Sons and D...|Wardell recalls h...|  ['Steven Wardell']|  Plympton PressIntl|         1995|  ['Social Science']|793.5048996688412|              1995|                   |\n",
      "| 10|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|    Berg Pub Limited|   1994-02-17|        ['Religion']|759.2711582939609|              1994|                 02|\n",
      "| 11|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|             OUP USA|      2005-07|       ['Reference']|847.0213715319953|              2005|                 07|\n",
      "| 12|Mensa Number Puzz...|Acclaimed teacher...|['Evelyn B. Chris...|            Sky Pony|   2018-11-06|['Juvenile Nonfic...|759.2711582939609|              2018|                 11|\n",
      "| 13|Vector Quantizati...|Herb Caen, a popu...|['Allen Gersho', ...|Springer Science ...|   2012-12-06|['Technology & En...|800.7812983400412|              2012|                 12|\n",
      "| 14|A husband for Kutani|First published i...|      ['Frank Owen']|Pickle Partners P...|   2018-02-27|         ['History']|805.5685400829483|              2018|                 02|\n",
      "| 16|The Ultimate Guid...|This collection b...|    ['Fiona Cownie']|Bloomsbury Publis...|   2010-01-28|             ['Law']| 715.333258667078|              2010|                 01|\n",
      "| 17|The Repeal of Ret...|At a time when Am...|['Rochelle Gurste...|       Hill and Wang|   2016-01-05|['Political Scien...|819.1083355137085|              2016|                 01|\n",
      "| 18|Overcoming Hypert...|Like a time bomb ...|['Kenneth H. Coop...|              Bantam|   2012-02-01|['Health & Fitness']|805.5685400829483|              2012|                 02|\n",
      "| 19|    Alaska Sourdough|\"Sourdough is a m...|     ['Ruth Allman']|Alaska Northwest ...|         1976|         ['Cooking']|802.8286093005349|              1976|                   |\n",
      "| 20|The Oxford Handbo...|A guide to curren...|     ['Robert Kane']|             OUP USA|   2011-07-27|      ['Philosophy']|831.0666668926963|              2011|                 07|\n",
      "| 21|Eyewitness Travel...|The DK Eyewitness...|['Dorling Kinders...|Smithsonian Insti...|   2015-06-15|          ['Europe']|787.1883918642411|              2015|                 06|\n",
      "| 22|Hunting The Hard Way|Thrilling stories...|     ['Howard Hill']|     Derrydale Press|   2000-04-26|['Sports & Recrea...|866.5822716179268|              2000|                 04|\n",
      "| 23|History of Magic ...|See the history o...|              ['DK']|Dorling Kindersle...|   2020-08-06|['Body, Mind & Sp...|763.9246402507372|              2020|                 08|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:28:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_result.select([\"_c0\", \"publisher_count\"]), on=\"_c0\", how=\"left\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 2808 publishers and others category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat title and description\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.fillna(\"\").withColumn(f\"title_desc\", F.concat(col(\"title\"), col(\"description\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Title',\n",
       " 'description',\n",
       " 'authors',\n",
       " 'publisher',\n",
       " 'publishedDate',\n",
       " 'categories',\n",
       " 'Impact',\n",
       " 'publishedDate_year',\n",
       " 'publishedDate_month',\n",
       " 'publisher_count',\n",
       " 'title_desc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ('_c0', 'Title', 'description','publishedDate', 'publisher_count')\n",
    "df_final = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:28:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "23/12/31 00:28:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , publisher\n",
      " Schema: _c0, publisher\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+---------------+--------------------+\n",
      "|_c0|               Title|         description|             authors|           publisher|publishedDate|          categories|           Impact|publishedDate_year|publishedDate_month|publisher_count|          title_desc|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+---------------+--------------------+\n",
      "|467|The Devil in Sili...|This sweeping his...|['Stephen J. Pitti']|Princeton Univers...|   2018-06-05|         ['History']|841.7053210126119|              2018|                 06|            619|The Devil in Sili...|\n",
      "|691|Beat Up a Cookie:...|Ellie Bernstein i...|    ['Denise Dietz']|  Wildside Press LLC|      2009-04|['Detective and m...|799.1626097737924|              2009|                 04|            132|Beat Up a Cookie:...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+------------------+-------------------+---------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def identify_variable_types(df, unique_threshold=15000, id_vars=[]):\n",
    "#     \"\"\"\n",
    "#     Identify variable types in a PySpark DataFrame.\n",
    "\n",
    "#     :param df: The input PySpark DataFrame\n",
    "#     :param unique_threshold: The maximum number of unique values for a discrete variable. Default is 10.\n",
    "#     :id_vars: Unique keys like CustomerId, Names etc..\n",
    "#     :return: A dictionary with variable names as keys and variable types as values.\n",
    "#     \"\"\"\n",
    "\n",
    "#     discrete_columns = []\n",
    "#     categorical_columns = []\n",
    "#     continuous_columns = []\n",
    "#     Other_columns = id_vars\n",
    "#     df = df.drop(*Other_columns)\n",
    "\n",
    "#     for column in df.columns:\n",
    "#         dtype = df.schema[column].dataType\n",
    "\n",
    "#         if isinstance(dtype, StringType):\n",
    "#             unique_count = df.agg(countDistinct(col(column)).alias(\"unique_count\")).collect()[0][\"unique_count\"]\n",
    "#             if unique_count <= unique_threshold:\n",
    "#                 categorical_columns.append(column)\n",
    "#             else:\n",
    "#                 Other_columns.append(column)\n",
    "\n",
    "#         elif isinstance(dtype, IntegerType):\n",
    "#             unique_count = df.agg(countDistinct(col(column)).alias(\"unique_count\")).collect()[0][\"unique_count\"]\n",
    "#             if unique_count <= unique_threshold:\n",
    "#                 discrete_columns.append(column)\n",
    "#             else:\n",
    "#                 continuous_columns.append(column)\n",
    "\n",
    "#         elif isinstance(dtype, NumericType):\n",
    "#             continuous_columns.append(column)\n",
    "\n",
    "#     return discrete_columns, categorical_columns, continuous_columns, Other_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify variable types\n",
    "# discrete_columns, categorical_columns, continuous_columns, Other_columns = identify_variable_types(df, id_vars=['RowNumber', 'CustomerId'])\n",
    "\n",
    "# print(\"Discrete columns:\", discrete_columns)\n",
    "# print(\"Categorical columns:\", categorical_columns)\n",
    "# print(\"Continuous columns:\", continuous_columns)\n",
    "# print(\"Other columns:\", Other_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['publisher', 'categories', 'Impact', 'publishedDate_year', 'publishedDate_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_features = ['authors', 'publisher', 'categories']\n",
    "text_features = ['title_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.functions import vector_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_fit_category_to_one_hot_encode(column_name, output_col_name):\n",
    "    indexer = StringIndexer(inputCol=column_name, outputCol= output_col_name)\n",
    "    return indexer\n",
    "\n",
    "def pipeline_transform_category_to_one_hot_encode(column_name, output_col_name):\n",
    "\n",
    "    encoder = OneHotEncoder(inputCols=[column_name], outputCols=[output_col_name], dropLast=True)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['authors',\n",
       " 'publisher',\n",
       " 'categories',\n",
       " 'Impact',\n",
       " 'publishedDate_year',\n",
       " 'publishedDate_month',\n",
       " 'title_desc']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['publisher',\n",
       " 'categories',\n",
       " 'Impact',\n",
       " 'publishedDate_year',\n",
       " 'publishedDate_month']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['Title', 'description', 'authors', 'publisher', 'publishedDate', 'categories', 'Impact']\n",
    "df_final_v2 = df.select(*selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/31 00:30:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Title, description, authors, publisher, publishedDate, categories, Impact\n",
      " Schema: _c0, Title, description, authors, publisher, publishedDate, categories, Impact\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "23/12/31 00:30:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/harshita/Downloads/books_task.csv\n",
      "[Stage 89:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+\n",
      "|               Title|         description|             authors|           publisher|publishedDate|          categories|           Impact|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+\n",
      "|Its Only Art If I...|                    |    ['Julie Strain']|Smithsonian Insti...|         1996|['Comics & Graphi...|784.3039243054303|\n",
      "|Dr. Seuss: Americ...|Philip Nel takes ...|      ['Philip Nel']|           A&C Black|   2005-01-01|['Biography & Aut...|825.4655354138016|\n",
      "|Muslim Women's Ch...|Counters the West...|['Camillia Fawzi ...|    Berg Pub Limited|   1994-02-17|        ['Religion']|759.2711582939609|\n",
      "|Dramatica for Scr...|Dramatica for Scr...|['Armando Salda A...|             OUP USA|      2005-07|       ['Reference']|847.0213715319953|\n",
      "|Language:Social M...|Language: The Soc...|   ['Elaine Chaika']| Heinle & Heinle Pub|   2007-11-01|['Language Arts &...|831.0666668926963|\n",
      "|The Collected Wri...|                    |['William Edwy Vi...|Smithsonian Insti...|         1996|           ['Bible']|784.3039243054303|\n",
      "|Russia's Workers ...|\"How is it that t...|['Paul Thomas Chr...|Smithsonian Insti...|         1999|['Business & Econ...|784.3039243054303|\n",
      "|Secret Anniversar...|\"A collection of ...|     ['Lev Raphael']|      Leapfrog Press|         2006|         ['Fiction']|831.0666668926963|\n",
      "|Mechanics: From N...|Purpose and Empha...|  ['Florian Scheck']|Springer Science ...|   2010-04-01|         ['Science']|805.5685400829483|\n",
      "|Are You Ready for...|“Peter Doggett’s ...|   ['Peter Doggett']|      Harper Collins|   2010-06-08|           ['Music']|793.5048996688412|\n",
      "|Cardinal Sins (Ma...|                    |['Terence Reese',...|     Victor Gollancz|         1991|           ['Games']|805.5685400829483|\n",
      "|Second Chance:(Le...|Four former Chris...|['Jerry B. Jenkin...|Tyndale House Pub...|         1998|['Juvenile Fiction']|820.2711298637219|\n",
      "|          Soul Resin|Soul Resin is a s...|['Charles W. Cann...|University of Ala...|         2002|         ['Fiction']|774.7240160569136|\n",
      "|Probability Trilo...|A long time ago I...|  ['David Freedman']|            Springer|   1983-01-12|     ['Mathematics']|805.5685400829483|\n",
      "|Renal and Electro...|Geared to residen...|['Robert W. Schri...|Lippincott Willia...|   2012-03-29|         ['Medical']|831.0666668926963|\n",
      "|Japanese Garden D...|Japanese Garden D...|['Marc Peter Keane']|   Tuttle Publishing|   2017-02-21|       ['Gardening']|839.3731438824466|\n",
      "|Mean Rooms (Five ...|\"Blood types\" and...|     ['Julie Smith']|      Five Star (ME)|         2000|         ['Fiction']| 739.325432554045|\n",
      "|Hidden Jewel (Lan...|Pearl hopes for h...|['Virginia Andrews']|  Simon and Schuster|   2012-12-25|         ['Fiction']|816.7454074993453|\n",
      "|              Marrow|Bone Marrow Patho...|['Barbara J. Bain...|   John Wiley & Sons|   2019-04-15|         ['Medical']|763.0393085279125|\n",
      "|How My Family Cam...|Includes a book j...|['Andrew R. Aldri...|             OUP USA|         2003|['Juvenile Nonfic...|853.2807523510916|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final_v2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final_v2.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = []\n",
    "for col_name in cat_columns:\n",
    "    stages.append(pipeline_fit_category_to_one_hot_encode(col_name, col_name+\"_numeric\"))\n",
    "    # stages.append(pipeline_transform_category_to_one_hot_encode(col_name+\"_numeric\", col_name +'_onehot'))\n",
    "\n",
    "pipeline = Pipeline(stages = stages)\n",
    "df_transformed = pipeline.fit(df_final).transform(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
